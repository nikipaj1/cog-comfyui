{
  "10": {
    "class_type": "LoadImage",
    "inputs": {
      "image": "reference.png",
      "upload": "image"
    }
  },
  "11": {
    "class_type": "LoadImage",
    "inputs": {
      "image": "clothing.png",
      "upload": "image"
    }
  },
  "12": {
    "class_type": "LoadAutoMasker",
    "inputs": {
      "model_name": "zhengchong/CatVTON",
      "catvton_path": "zhengchong/CatVTON"
    }
  },
  "13": {
    "class_type": "AutoMasker",
    "inputs": {
      "pipe": ["12", 0],
      "target_image": ["46", 0],
      "mask_type": "overall",
      "cloth_type": "overall"
    }
  },
  "14": {
    "class_type": "PreviewImage",
    "inputs": {
      "images": ["13", 1]
    }
  },
  "15": {
    "inputs": {
      "images": ["13", 0]
    },
    "class_type": "PreviewImage"
  },
  "16": {
    "class_type": "CatVTON",
    "inputs": {
      "pipe": ["17", 0],
      "target_image": ["46", 0],
      "refer_image": ["11", 0],
      "mask_image": ["13", 0],
      "cfg": 3.5,
      "steps": 50,
      "seed": 42
    }
  },
  "17": {
    "class_type": "LoadCatVTONPipeline",
    "inputs": {
      "base_model_name": "runwayml/stable-diffusion-inpainting",
      "model_name": "zhengchong/CatVTON",
      "model_precision": "fp16",
      "catvton_path": "zhengchong/CatVTON",
      "mixed_precision": "fp16",
      "sd15_inpaint_path": "runwayml/stable-diffusion-inpainting"
    }
  },
  "18": {
    "class_type": "PreviewImage",
    "inputs": {
      "images": ["16", 0]
    }
  },
  "27": {
    "inputs": {
      "method": "intensity",
      "image": ["13", 0]
    },
    "class_type": "Image To Mask",
    "_meta": {
      "title": "Image To Mask"
    }
  },
  "28": {
    "class_type": "CheckpointLoaderSimple",
    "inputs": {
      "ckpt_name": "juggernautXL_v8Rundiffusion.safetensors"
    }
  },
  "29": {
    "class_type": "CLIPTextEncode",
    "inputs": {
      "text": ["45", 0],
      "clip": ["28", 1]
    }
  },
  "30": {
    "class_type": "CLIPTextEncode",
    "inputs": {
      "text": "",
      "clip": ["28", 1]
    }
  },
  "31": {
    "inputs": {
      "seed": 7867687,
      "steps": 30,
      "cfg": 3.5,
      "sampler_name": "dpmpp_sde",
      "scheduler": "karras",
      "denoise": 0.4,
      "model": ["36", 0],
      "positive": ["29", 0],
      "negative": ["30", 0],
      "latent_image": ["35", 0]
    },
    "class_type": "KSampler"
  },
  "32": {
    "inputs": {
      "samples": ["31", 0],
      "vae": ["28", 2]
    },
    "class_type": "VAEDecode"
  },
  "33": {
    "inputs": {
      "filename_prefix": "ComfyUI",
      "images": ["32", 0]
    },
    "class_type": "SaveImage"
  },
  "34": {
    "inputs": {
      "pixels": ["40", 0],
      "vae": ["28", 2]
    },
    "class_type": "VAEEncode"
  },
  "35": {
    "inputs": {
      "samples": ["34", 0],
      "mask": ["41", 0]
    },
    "class_type": "SetLatentNoiseMask"
  },
  "36": {
    "inputs": {
      "weight": 0.8,
      "weight_type": "linear",
      "combine_embeds": "concat",
      "start_at": 0,
      "end_at": 1,
      "embeds_scaling": "V only",
      "model": ["37", 0],
      "ipadapter": ["37", 1],
      "image": ["11", 0],
      "attn_mask": ["27", 0]
    },
    "class_type": "IPAdapterAdvanced",
    "_meta": {
      "title": "IPAdapter Advanced"
    }
  },
  "37": {
    "inputs": {
      "preset": "PLUS (high strength)",
      "model": ["28", 0]
    },
    "class_type": "IPAdapterUnifiedLoader",
    "_meta": {
      "title": "IPAdapter Unified Loader"
    }
  },
  "38": {
    "inputs": {
      "rgthree_comparer": {
        "images": [
          {
            "name": "A",
            "selected": true,
            "url": "/api/view?filename=rgthree.compare._temp_xfxqc_00005_.png&type=temp&subfolder=&rand=0.8031914080431928"
          },
          {
            "name": "B",
            "selected": true,
            "url": "/api/view?filename=rgthree.compare._temp_xfxqc_00006_.png&type=temp&subfolder=&rand=0.9954941402052169"
          }
        ]
      },
      "image_a": ["16", 0],
      "image_b": ["32", 0]
    },
    "class_type": "Image Comparer (rgthree)"
  },
  "40": {
    "inputs": {
      "x": 0,
      "y": 0,
      "resize_source": false,
      "destination": ["46", 0],
      "source": ["16", 0],
      "mask": ["41", 0]
    },
    "class_type": "ImageCompositeMasked"
  },
  "41": {
    "inputs": {
      "amount": 10,
      "device": "auto",
      "mask": ["27", 0]
    },
    "class_type": "MaskBlur+"
  },
  "42": {
    "inputs": {
      "images": ["40", 0]
    },
    "class_type": "PreviewImage"
  },
  "43": {
    "inputs": {
      "text_input": "",
      "task": "detailed_caption",
      "fill_mask": true,
      "keep_model_loaded": false,
      "max_new_tokens": 1024,
      "num_beams": 3,
      "do_sample": true,
      "output_mask_select": "",
      "seed": 178128789115776,
      "image": ["11", 0],
      "florence2_model": ["44", 0]
    },
    "class_type": "Florence2Run",
    "_meta": {
      "title": "Florence2Run"
    }
  },
  "44": {
    "inputs": {
      "model": "microsoft/Florence-2-large",
      "precision": "fp16",
      "attention": "sdpa"
    },
    "class_type": "DownloadAndLoadFlorence2Model",
    "_meta": {
      "title": "DownloadAndLoadFlorence2Model"
    }
  },
  "45": {
    "inputs": {
      "text": ["43", 2],
      "text2": "clothing"
    },
    "class_type": "ShowText|pysssss"
  },
  "46": {
    "inputs": {
      "width": 768,
      "height": 1024,
      "upscale_method": "nearest-exact",
      "keep_proportion": false,
      "divisible_by": 2,
      "crop": "center",
      "image": ["10", 0]
    },
    "class_type": "ImageResizeKJ"
  },
  "54": {
    "inputs": {
      "MODEL": ["28", 0],
      "CLIP": ["28", 1],
      "VAE": ["28", 2]
    },
    "class_type": "Anything Everywhere3"
  }
}
